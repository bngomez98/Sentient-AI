interface PretrainedDataEntry {
  id: string
  title: string
  content: string
  keywords?: string[]
  category?: string
  date?: string
}

export const pretrainedData: PretrainedDataEntry[] = [
  {
    id: "ai-overview",
    title: "Artificial Intelligence Overview",
    content: `Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.

The ideal characteristic of artificial intelligence is its ability to rationalize and take actions that have the best chance of achieving a specific goal. A subset of artificial intelligence is machine learning, which refers to the concept that computer programs can automatically learn from and adapt to new data without being assisted by humans.

Deep learning techniques enable this automatic learning through the absorption of huge amounts of unstructured data such as text, images, or video.`,
    keywords: ["artificial intelligence", "AI", "machine learning", "deep learning", "intelligence"],
    category: "Technology",
    date: "2023-01-15",
  },
  {
    id: "machine-learning",
    title: "Machine Learning Fundamentals",
    content: `Machine Learning is a subset of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.

The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.

Machine learning algorithms are often categorized as supervised (using labeled training data), unsupervised (using unlabeled training data), or reinforcement learning (learning through trial and error with rewards and penalties).`,
    keywords: [
      "machine learning",
      "supervised learning",
      "unsupervised learning",
      "reinforcement learning",
      "algorithms",
    ],
    category: "Technology",
    date: "2023-01-20",
  },
  {
    id: "neural-networks",
    title: "Neural Networks Explained",
    content: `Neural Networks are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn to perform tasks by considering examples, generally without being programmed with task-specific rules.

A neural network is based on a collection of connected units called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals, processes them, and can signal neurons connected to it.

The "signal" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. Neurons and connections typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection.

Neural networks are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.`,
    keywords: ["neural networks", "artificial neurons", "deep learning", "layers", "weights", "backpropagation"],
    category: "Technology",
    date: "2023-02-05",
  },
  {
    id: "nlp-overview",
    title: "Natural Language Processing",
    content: `Natural Language Processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret, and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics.

NLP enables computers to read text, hear speech, interpret it, measure sentiment, and determine which parts are important. Today's machines can analyze more language-based data than humans, without fatigue and in a consistent, unbiased way.

The development of NLP applications is challenging because computers traditionally require humans to "speak" to them in a programming language that is precise, unambiguous, and highly structuredâ€”or through a limited number of clearly enunciated voice commands. Human speech, however, is not always precise; it is often ambiguous and the linguistic structure can depend on many complex variables, including slang, regional dialects, and social context.

Modern NLP algorithms use machine learning, especially statistical machine learning, to learn rules through the analysis of large corpora of real-world examples. Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks.`,
    keywords: [
      "natural language processing",
      "NLP",
      "computational linguistics",
      "text analysis",
      "sentiment analysis",
      "language understanding",
    ],
    category: "Technology",
    date: "2023-02-15",
  },
  {
    id: "computer-vision",
    title: "Computer Vision Technology",
    content: `Computer Vision is a field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects and then react to what they "see."

Computer vision works in three basic steps: acquiring an image, processing the image, and understanding the image. Image acquisition can be as simple as retrieving a digital image from a database or as complex as extracting 3D models from 2D images. Image processing involves methods like noise reduction, contrast enhancement, and image sharpening to bring out features of interest. Image understanding is the final stage where the processed image is analyzed to extract meaningful information.

Applications of computer vision include autonomous vehicles, facial recognition, augmented reality, medical image analysis, and industrial quality inspection. The field has seen rapid advancement with the rise of deep learning, particularly convolutional neural networks (CNNs), which have proven highly effective for image classification, object detection, and segmentation tasks.`,
    keywords: [
      "computer vision",
      "image processing",
      "object detection",
      "facial recognition",
      "convolutional neural networks",
      "CNN",
    ],
    category: "Technology",
    date: "2023-03-01",
  },
  {
    id: "reinforcement-learning",
    title: "Reinforcement Learning Principles",
    content: `Reinforcement Learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning differs from supervised learning in that labeled input/output pairs need not be presented, and sub-optimal actions need not be explicitly corrected.

The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context utilize dynamic programming techniques. The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.

Key concepts in reinforcement learning include the agent, the environment, states, actions, rewards, and policies. The agent is the learner or decision-maker. The environment is everything the agent interacts with. A state is a concrete and immediate situation in which the agent finds itself. An action is a move made by the agent. A reward is the feedback from the environment. A policy is the strategy that the agent employs to determine the next action based on the current state.

Reinforcement learning has been applied successfully to various problems, including game playing (like AlphaGo), robotics, resource management, and recommendation systems.`,
    keywords: [
      "reinforcement learning",
      "RL",
      "Markov decision process",
      "MDP",
      "agent",
      "environment",
      "reward",
      "policy",
    ],
    category: "Technology",
    date: "2023-03-15",
  },
  {
    id: "quantum-computing",
    title: "Quantum Computing Basics",
    content: `Quantum computing is a type of computation that harnesses the collective properties of quantum states, such as superposition, interference, and entanglement, to perform calculations. The devices that perform quantum computations are known as quantum computers.

While traditional computers use bits as the smallest unit of data (either a 0 or a 1), quantum computers use quantum bits, or qubits. Qubits can exist in multiple states simultaneously due to a property called superposition, which allows quantum computers to process a vast number of calculations simultaneously.

Another key property is entanglement, where qubits that are entangled can be in a correlated state such that the quantum state of each qubit cannot be described independently of the state of the others. This property allows quantum computers to process information in ways that classical computers cannot.

Quantum computing has the potential to revolutionize fields such as cryptography, material science, drug discovery, optimization problems, and artificial intelligence. However, building practical quantum computers is extremely challenging due to issues like quantum decoherence and the need for error correction.`,
    keywords: ["quantum computing", "qubits", "superposition", "entanglement", "quantum states", "quantum algorithms"],
    category: "Technology",
    date: "2023-04-01",
  },
  {
    id: "edge-computing",
    title: "Edge Computing Architecture",
    content: `Edge computing is a distributed computing paradigm that brings computation and data storage closer to the location where it is needed, to improve response times and save bandwidth. The term "edge" refers to the edge of the network, where the physical device or data source exists.

In traditional cloud computing, data processing happens in centralized data centers. In edge computing, data processing occurs at or near the source of the data, reducing the need to transfer data back and forth between the cloud and the device.

Edge computing is particularly important for Internet of Things (IoT) devices, which generate vast amounts of data. By processing this data locally, edge computing reduces latency, conserves network bandwidth, enhances privacy, and enables operations even with intermittent connectivity to the cloud.

Key components of edge computing architecture include edge devices (like IoT sensors, smartphones, or edge servers), edge gateways (which aggregate data from multiple sources), and the cloud (which provides centralized management and advanced analytics).

Applications of edge computing include autonomous vehicles, smart cities, industrial IoT, augmented reality, and content delivery networks.`,
    keywords: [
      "edge computing",
      "distributed computing",
      "IoT",
      "Internet of Things",
      "latency",
      "bandwidth",
      "data processing",
    ],
    category: "Technology",
    date: "2023-04-15",
  },
  {
    id: "blockchain-tech",
    title: "Blockchain Technology",
    content: `Blockchain is a distributed ledger technology that enables secure, transparent, and tamper-resistant record-keeping. It consists of a chain of blocks, each containing a list of transactions, with each block linked to the previous one using cryptographic hashes.

The key features of blockchain include decentralization (no single entity controls the network), transparency (all transactions are visible to participants), immutability (once recorded, data cannot be altered), and security (cryptographic techniques protect the integrity of the data).

Blockchain operates on a peer-to-peer network where each participant (or node) maintains a copy of the ledger. When a new transaction occurs, it is broadcast to the network and validated by nodes through a consensus mechanism. Once validated, the transaction is added to a block, which is then added to the chain.

Common consensus mechanisms include Proof of Work (used by Bitcoin), where nodes compete to solve complex mathematical puzzles, and Proof of Stake (used by Ethereum 2.0), where validators are chosen based on the amount of cryptocurrency they hold and are willing to "stake" as collateral.

Applications of blockchain extend beyond cryptocurrencies to include supply chain management, digital identity verification, voting systems, and smart contracts (self-executing contracts with the terms directly written into code).`,
    keywords: [
      "blockchain",
      "distributed ledger",
      "decentralization",
      "consensus",
      "proof of work",
      "proof of stake",
      "smart contracts",
    ],
    category: "Technology",
    date: "2023-05-01",
  },
  {
    id: "serverless-computing",
    title: "Serverless Computing",
    content: `Serverless computing is a cloud computing execution model where the cloud provider dynamically manages the allocation and provisioning of servers. A serverless application runs in stateless compute containers that are event-triggered, ephemeral (may last for one invocation), and fully managed by the cloud provider.

Despite the name, serverless computing doesn't mean there are no servers involved; it means that the developer doesn't have to think about servers. The cloud provider handles all the infrastructure management tasks like capacity provisioning, patching, scaling, and maintenance.

Key characteristics of serverless computing include:
1. No server management: Developers focus on writing code, not managing infrastructure.
2. Pay-per-use pricing: You only pay for the compute time you consume, not for idle capacity.
3. Auto-scaling: The platform automatically scales based on the number of requests.
4. Event-driven: Functions are triggered by events like HTTP requests, database changes, or file uploads.

Common serverless platforms include AWS Lambda, Azure Functions, Google Cloud Functions, and IBM Cloud Functions. Serverless is particularly well-suited for microservices architectures, real-time file processing, scheduled tasks, and backend APIs.

While serverless offers many advantages, it also has limitations such as cold start latency, vendor lock-in, limited execution duration, and debugging challenges.`,
    keywords: [
      "serverless",
      "cloud computing",
      "FaaS",
      "function as a service",
      "event-driven",
      "auto-scaling",
      "microservices",
    ],
    category: "Technology",
    date: "2023-05-15",
  },
]

